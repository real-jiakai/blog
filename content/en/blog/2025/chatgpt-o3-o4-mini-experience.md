---
title: "ChatGPT o3, o4 mini Experience"
date: 2025-04-17T09:06:26+08:00
tags: ['chatgpt']
slug: "chatgpt-o3-o4-mini-experience"
summary: Sharing my ChatGPT o3, o4 mini experience.
showtoc: true
---

## Update (2025.4.29)

Personally I feel ChatGPT 4o model has improved a lot compared to last year. Recently saw an L Site post‚Äî[Is 4o's sycophantic style GPT dumbing down](https://linux.do/t/topic/589282)‚Äîcan't help but think for newbie users, 4o's sycophantic style is indeed friendly.

Currently for some daily questions (not involving programming, writing), I'm leaning toward ChatGPT 4o. Comparing today's Qwen3 release‚ÄîQwen3 benefits open-source which is commendable, but for daily topics, I personally think it's slightly inferior to closed-source models. [Though one example below isn't enough to show the gap]

![ChatGPT 4o model associates "see tinh" with Vietnamese female singer](https://cdn.sa.net/2025/04/29/ZcxJ5fvpwrD1QYi.webp)

Nobody rejects a sycophant [as long as they catch your eye]. I definitely won't reject Doubao's sweet girl voice or ChatGPT 4o's sycophantic style. üòÅ

![](https://cdn.sa.net/2025/04/29/BFuMJVZaK5ARcn2.webp)

"OpenAI though Closed is always at the top of the entire industry"‚Äîthis statement makes so much sense! Non-dumbed-down OpenAI has unbeatable experience in all aspects.
via: https://linux.do/t/topic/602275/

## Update (2025.4.26)

Today ChatGPT 4o on official site updated again. via: https://x.com/sama/status/1915902652703248679

After using official site 4o a few times, for technical questions, ChatGPT 4o now prioritizes English internet search. This is good. Previously Chinese questions searched Chinese internet.

![ChatGPT 4o internet search now prioritizes English internet](https://cdn.sa.net/2025/04/26/ARodUtDXge6bwaq.webp)

Recently I increasingly feel products like Perplexity will die in the future. Since o3, o4-mini series models came out, my Perplexity usage dropped sharply.

## Update (2025.4.24)

ChatGPT Plus users' o3, o4-mini-high quota doubled. o3: 100/week; o4-mini-high: 100/day.

via: https://help.openai.com/en/articles/9824962-openai-o3-and-o4-mini-usage-limits-on-chatgpt-and-the-api

## Update (2025.4.20)

Can't completely embrace Claude either. Currently ChatGPT's latest o3, o4-mini series full-auto agent LLM calling various tools for debugging is really comfortable. Code comments might not match original o3-mini-high, but everything else is far ahead. Previously for internet debugging I might use Perplexity etc. for assistance. With latest o3, o4-mini-high‚Äîfull-auto debugging, Chinese programming questions, English internet search, until task complete.

For example, this morning while learning I encountered a bug. Asked various LLMs‚Äîonly ChatGPT's full-auto agent successfully solved it. Other LLMs I didn't even want to follow up‚Äîinitial answers were problematic. Plus solving this bug needed searching latest knowledge‚Äîway more effort than ChatGPT's full-auto agent.

![ChatGPT Agent LLM full-auto Debug](https://cdn.sa.net/2025/04/20/JUanqtRECYm8oeX.webp)

I can only say current LLMs are truly dazzling. Sometimes don't know which model to use. Because I personally have strong Claude inertia, yesterday I wrote Claude praise, but recent Gemini 2.5 Pro, ChatGPT o3, o4-mini series updates are also really top‚Äîall SOTA. Having choice paralysis.

## Update (2025.4.19)

Recently o3 guessing image locations went viral. But besides image guessing, the rest feels below expectations. Like code comments‚ÄîI somewhat miss o3-mini-high. Current tool-using o3 or o4-mini-high has insufficient thinking time‚Äîcode comment quality worse than original o3-mini-high.

Whenever I learn new knowledge, I still first consider Claude. Gemini 2.5 Pro can't achieve Claude's rich yet not overly verbose communication experience. Claude sometimes has excellent generalization (so-called soul)‚Äîincisive replies to questions feel surprising yet unexpected. Though I compare all current LLMs, overall after getting used to Claude's reply style, so far no LLM catches my eye. No matter how Gemini 2.5 Pro, o3, o4-mini-high dominate benchmarks, my heart always belongs to Claude.

![My heart belongs to Claude](https://cdn.sa.net/2025/04/19/eM52tVaz1UkKqc4.webp)

## Update (2025.4.18)

- Context decay resistance

o3's powerful context decay resistance surpasses Gemini 2.5 Pro. Still the big brother OpenAI‚Äîfar ahead. Pro users with unlimited o3 probably won't even glance at o4-mini-high. In a few weeks o3-pro comes out.

![OpenAI o3's exaggerated context decay resistance](https://cdn.sa.net/2025/04/17/GPurxLq3o5Nk9Qt.webp)

via: [Fiction.liveBench April 17 2025](https://fiction.live/stories/Fiction-liveBench-Mar-25-2025/oQdzQvKHw8JyXbN87)

- Daily usage choice

For not-too-complex questions, prioritize o4-mini-high‚Äîafter all, Plus users have limited weekly o3 quota. Personally, agent mode o-series has excellent user experience.

![Agent mode o-series has excellent user experience](https://cdn.sa.net/2025/04/18/X6pd2G4VK3QwLSg.webp)

## Update (2025.4.17)

Adding some good review content I've seen.

- [Original Long Post: Everything about GPT-O3, O3-Pro, O4-mini and 4.1: Livebench, Aider Coding, SimpleBench All Top, Free Trial Channels [Long-term Update]](https://linux.do/t/topic/566707)

## Update Summary

- Usage limits

ChatGPT Plus users: o3 limit 50/week; o4-mini limit 150/day; o4-mini-high 50/day; 32K context window.

via:

https://help.openai.com/en/articles/9824962-openai-o3-o4-mini-and-o3-mini-usage-limits-on-chatgpt-and-the-api

https://openai.com/chatgpt/pricing/

Don't recommend free users use ChatGPT. Without paying, experience is definitely terrible‚Äîonly 8K context window, and only lower-tier models available.

In OpenAI's rules, Pro users are gods, Plus users are commoners, free users are beggars.

Also don't recommend friends with obvious proxy characteristics to use ChatGPT‚Äîdumbing down is real. Suggest remote Windows desktop/self-hosted KasmWorkspaces methods [prerequisite: remote VPS IP should be clean, otherwise still dumbed down] to access ChatGPT.

- Reasoning model becomes agent, combining every ChatGPT tool (web search, Python interpreter, image analysis, file interpretation, image generation), can do visual reasoning [multimodal reasoning]

Image below shows part of image recognition task‚Äîfeel ChatGPT o3 model's terrifying iteration capability.

![ChatGPT o3 model's terrifying iteration capability](https://cdn.sa.net/2025/04/17/8Qlq9ZjUntdbWgm.webp)

This image recognition task flow‚Äîsee this task's <a href="/document/2025-04-17-chatgpt-o3-image-thinking-demo.html" target="_blank">webpage screenshot</a>:

1. 1m21s reasoning time

Find drone in image.

2. 44s reasoning time

Initial guess of possible photo locations [guess list already contained correct answer, unfortunately bet on one‚Äîmost likely guess was wrong.]

3. 2min59s, 4min41s, 11min14s, 12min41s, 13min56s reasoning time

In these parts, o3 uses internet tools to guess possible locations, but possibly hit reasoning time or context limit, causing truncation‚Äîonly outputting `to=`.

Couldn't watch o3 deviate from correct answer, going further in wrong direction. I revealed some hints‚Äîlike initial guess list has correct answer.

4. 6min51s, 11min45s, 13min51s reasoning time

I saw o3 flip-flopping between correct and wrong answers, falling into same predicament‚Äîonly outputting `to=`. Continued revealing hints‚Äîdon't fixate on one area's universities, don't limit to library-type buildings.

5. 7min14s, 9min31s, 11min58s reasoning time

o3 again interrupted. I continued prompting‚Äîcombine above analysis, give most likely location.

6. 10s reasoning time

o3 successfully guessed the location, but small location was wrong.

7. 11min56s reasoning time

o3 with search successfully guessed small location, but response contained wrong info.

8. Finally I asked o3 to convert original image to Ghibli style

![I asked o3 to convert original to Ghibli style](https://cdn.sa.net/2025/04/17/ZKuF4UShy5iXBd6.webp)

Looking back‚Äîthis is truly a cheesy strategy, but also how agents should be‚Äîusing external tools to iterate until task complete.

First time experiencing LLM reasoning over 10 minutes. ChatGPT really tries hard.

- Daily usage: choose o3 or o4-mini-high?

From OpenAI's benchmarks, except these three (first two test math competitions, third is algorithm programming competition) where o4-mini-high leads o3, the rest o3 wins.

![Three benchmarks where o4-mini-high leads o3](https://cdn.sa.net/2025/04/17/miHD5Sz7jTeAF2p.webp)

OpenAI employee recommends o4-mini-high over o3 for visual tasks. via: https://simonwillison.net/2025/Apr/16/james-betker/

![OpenAI employee recommends o4-mini-high for visual tasks, not o3](https://cdn.sa.net/2025/04/17/ZjoHUEYfOm1sWFe.webp)

Though benchmarks have biases, they roughly show LLM general capabilities. OpenAI's new models dominate livebench.ai‚Äîreasoning models are indeed benchmark kings.

![OpenAI new models dominate livebench.ai‚Äîreasoning models are benchmark kings](https://cdn.sa.net/2025/04/17/uP8UYzlvTejCWGi.webp)

Plus users have 50/week o3 quota‚Äîuse it. After exhausting o3, use o4-mini-high.

- New models' search: Chinese questions no longer limited to Chinese internet

After Chinese questions, OpenAI's new o3, o4-mini series directly search internet with English and Chinese versions of the question. GPT-4o still follows Chinese questions, Chinese internet search.

![New models' search: Chinese questions no longer limited to Chinese internet - image 1](https://cdn.sa.net/2025/04/17/KluykJ8ecB2RqXm.webp)

![New models' search: Chinese questions no longer limited to Chinese internet - image 2](https://cdn.sa.net/2025/04/17/tO6ydPsSGq5UBwQ.webp)

Reinforcement learning training models to use tools is truly impressive‚Äînot just teaching how to use tools, but reasoning when to use them.

![Reinforcement learning training models to use tools is truly impressive](https://cdn.sa.net/2025/04/17/zTfDgWeGLSKxCsM.webp)

- Codex

Similar to Claude Code. I tried applying for open-source funding‚Äîif they give me some API quota, I'll try. Not considering for now. Foreigners think OpenAI finally gets it‚Äîstarting to learn from Anthropic developing models for real needs.

- Other discoveries

1. OpenAI's new models are token efficient (use as few tokens as possible for same or better information expression and reasoning).

I think this is the future trend for reasoning models. Current OpenAI new models already feel like reasoning models + classic LLM combined.

![OpenAI new models don't think for simple questions](https://cdn.sa.net/2025/04/17/4yv3AefFqsI758a.webp)

2. Gemini 2.5 Pro remains cost-effectiveness king.

![Gemini 2.5 Pro remains cost-effectiveness king - image 1](https://cdn.sa.net/2025/04/17/BQ8EaTvIMLbNh3J.webp)

via: https://x.com/MahawarYas27492/status/1912577363554214214

Comparing aider leaderboard top spending shows Gemini 2.5 Pro is truly cost-effective. DeepSeek V3 March update is also cost-effective but capability-wise inferior to Gemini 2.5 Pro.

![Comparing aider leaderboard top spending shows Gemini 2.5 Pro is truly cost-effective](https://cdn.sa.net/2025/04/17/rl3VisoSOK6NLgT.webp)

![Gemini 2.5 Pro remains cost-effectiveness king - image 2](https://cdn.sa.net/2025/04/17/M1nKdHlwxYO3Suo.webp)

via: https://x.com/bongrandp/status/1912568582426198301

![Gemini 2.5 Pro remains cost-effectiveness king - image 3](https://cdn.sa.net/2025/04/17/Ti2lk9qzxhLcvAM.webp)

via: https://x.com/wintermoat/status/1912560505161400781

## Summary

OpenAI new models' main highlights are tool calling and multimodal reasoning.

This time OpenAI's blog benchmarks only listed their own models. Is this arrogance‚ÄîOpenAI thinks their models are strongest? Or not daring to compare with other advanced models, fearing their massive users learn about other advanced LLMs? Only OpenAI knows.

But this release is much better than before. GPT-4.5, GPT-4.1 releases in today's rapid iteration barely make waves. Only releases like GPT-4o native text-to-image, o3, o4-mini series are the right path.

Can say OpenAI Is Back! Though I hope to see open-source LLMs closer to closed-source, currently closed-source LLMs again widen the gap.

Looking forward to Qwen3, DeepSeek R2 performing better soon.

One more thing‚ÄîOpenAI still releases reasoning models. Friends who like non-reasoning models‚Äîstill don't underestimate Claude 3.7 Sonnet Without Thinking!!!!!

## Other

Attaching some other bloggers' reviews

- [OpenAI Launches Full o3 and o4 mini Late Night - Still Leading.](https://mp.weixin.qq.com/s/M_1il2a66B7v2rysDJ6-zA)

## References

- [Introducing OpenAI o3 and o4-mini](https://openai.com/index/introducing-o3-and-o4-mini/)

- [Thinking with images](https://openai.com/index/thinking-with-images/)

- [OpenAI o3 and o4-mini System Card](https://openai.com/index/o3-o4-mini-system-card/)
