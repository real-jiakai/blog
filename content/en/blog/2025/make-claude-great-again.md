---
title: "Make Claude Great Again!"
date: 2025-08-06T18:28:21+08:00
tags: ['claude']
slug: "make-claude-great-again"
summary: Sharing recent Claude product usage insights.
showtoc: false
---

![Make Claude Great Again!](https://cdn.sa.net/2025/08/06/76IRckCSMdUpXFt.webp)

Dark horse among AI labs[^1]—Anthropic released Claude Opus 4.1 early this morning.

Recently when using Claude Opus 4 to assist writing certain thesis sections, my impression was that writing quality has been declining. With the same Prompt (the part for LLM to improve, writing ideas, key points all pre-filled), Gemini 2.5 Pro in AI Studio produced paragraphs with clear logic that I could polish and use directly. Claude Opus 4's output was mostly list-style presentation—less text that could be directly polished.

Of course it might be my Prompt wasn't good enough. Currently for thesis writing assistance, first LLMs that come to mind are still Claude Opus and Gemini 2.5 Pro.

Today's released model page[^2] has this statement about content creation:

![Claude Opus model page statement about content creation](https://cdn.sa.net/2025/08/06/3NsC1ap9ijXgGUE.webp)

Though can't underestimate Claude Opus series' writing level. But Anthropic keeps strengthening Claude series' coding and Agent capabilities, making me somewhat worried about potential regression in writing skills.

Claude 4 series models training cutoff: March 2025.

![Claude 4 series models training cutoff: March 2025](https://cdn.sa.net/2025/08/06/a97kbLCGx6d3YtW.webp)

This is what I overlooked in May's Claude 4 blog. Though cutoff date doesn't prove much—when asking models to write business code using certain frameworks, they still use outdated framework SDK knowledge. Like Gemini's Python SDK—Claude 4 series still uses deprecated SDK.

Cutoff date should be the latest among all current models. I previously mistakenly thought Gemini 2.5 Pro had the latest knowledge cutoff (January 2025).

Claude 4 series models know about January 2025 California wildfires without enabling search.

![Claude 4 series models know about January 2025 California wildfires without enabling search](https://cdn.sa.net/2025/08/06/XSfng6MixNuaZ32.webp)

Currently many LLM providers focus on post-training—pre-training has even been abandoned, after all with web search tools, models can get latest information in real-time. Appreciate Anthropic doing both pre-training and post-training.

Claude Opus 4.1 model card[^3] is all safety content. Personally now and in future I won't believe LLMs will pose any threat to humans. Though current models look intelligent, they're actually just so-so.

Claude Code started becoming popular around June 2025, becoming a favored tool among programmers. Its current hype definitely exceeds Augment, Cursor and similar products.

I also tried Vibe Coding with this tool in July. Claude Code experience is indeed good—being able to directly operate Jupyter Notebooks opened my eyes (also tried installing Claude Code in Google Colab terminal—Claude Code couldn't operate corresponding Jupyter Notebook cells).

![Claude Code directly operating Jupyter Notebook opened my eyes](https://cdn.sa.net/2025/08/06/1kAgv2K6acBG7Eb.webp)

Domestic cheap GPU platform is AutoDL. No-GPU mode costs 0.1 yuan per hour. Sometimes scripts that need long runtimes I run there. When script has bugs, directly install Claude Code in terminal and can start happily assisting my code. Claude Code doesn't officially provide GUI—terminal format is indeed more universal. Though there are open-source Claude Code GUI companion projects.

![Claude Code terminal format is more universal](https://cdn.sa.net/2025/08/06/2GWMlhQBzVTengj.webp)

Of course being able to operate freely on domestic machines is because I'm using Claude Code relay. My own account won't login in Claude-unsupported regions.

The Claude Code relay I'm using is also unstable—almost every day there are accounts getting banned by Anthropic. Currently can only use Claude Sonnet 4 model.

Claude Code shares quota with web version—this is a major reason for its popularity. If only API-supported Claude Code, whoever uses it goes bankrupt. With Max plan, directly start with Opus model—really great. Unfortunately Pro members can only use Sonnet model in Claude Code.

Using Claude Code and Claude Web, sometimes feeling like hitting quota lets me relax—can't help feeling tired. One person intensively using Pro membership—max 3 rounds a day, fully utilized, life is too exhausting.

![Using Claude intensively feels tiring](https://cdn.sa.net/2025/08/06/8axHdiyoLQv1gUw.webp)

Claude Sonnet 4's code ability I can't praise too much. Previously encountered a code bug—Vibe Coding with Sonnet 4 made it worse. Pure waste of my time. Not understanding code logic, can't hit targets precisely. Finally switched to Gemini CLI—Gemini 2.5 Pro passed first try. If someday Gemini CLI can share quota with Gemini web membership, definitely will see growth. Currently still underestimated.

Currently only Anthropic's Claude model has such harsh usage limits. Pro users with longer Claude Opus conversations hit limits in no time.

![Claude Opus model has harsh limits for Pro users](https://cdn.sa.net/2025/08/06/pmCY9QxakywF2Jr.webp)

GPT-5 releasing this week (US Thursday, Beijing Friday), but personally believe it still can't shake Claude model's strength in coding and Agents. What's GPT series strong at? Most versatile, search, text-to-image, ChatGPT Agent.

Wonder if OpenAI's benchmark this time dares to include Gemini 2.5 Pro, Grok 4, Claude Opus 4.1 comparisons. Even if included, I won't believe claims of leading Claude in coding and Agents.

Recently I started habitually using English with various overseas models. Initially thought English prompts would waste time, but after practicing found it doesn't waste much time. English expression using common words is enough. English phrases I can't recall—directly use Google Translate to supplement. Even if my English prompts have spelling errors, as long as not outrageous, AI basically understands.

What's most annoying about Claude models: `You're absolutely right!`

![What's most annoying about Claude models: You're absolutely right!](https://cdn.sa.net/2025/08/06/jrRnxy47cmPJ1Fk.webp)

Writing up to here, time has passed 8 PM. I should wash up and prepare to rest. Finally attaching my prediction for future Claude releases:

Official blog[^4] has this sentence:

```
We plan to release substantially larger improvements to our models
in the coming weeks.
```

`in the coming weeks` Chinese translation: next few weeks.

Claude Opus 4.1's most likely release time range is August 20 - September 3, 2025.

![Claude Opus 4.1's prediction for future Claude model improvement release timing](https://cdn.sa.net/2025/08/06/h2StNToMp4bwsy1.webp)

Claude Opus 4.1 predicts most likely release is Claude Opus 5, followed by new pricing tier, or longer context products.

![Claude Opus 4.1's prediction for future Claude model release content](https://cdn.sa.net/2025/08/06/XdK89fVZEWxclNG.webp)

Personally think its guesses have merit. After GPT-5 release, using massively improved models to crush OpenAI's proud products benefits further expanding Claude model market.

New pricing tier also possible. Late August, Claude Max plan will add weekly quota limits to prevent fanatics using Claude Code 24/7 automation. For unlimited Claude Opus model usage, introduce new plan tier—pay more monthly, like $1000 or $2000.

Longer context also possible. 200K context, enterprise 500K context—still hasn't reached Gemini's 1M context window. Extending to larger context like 1M or 2M helps compete with GPT-5, Gemini models. But actually long context has drawbacks—even with strong decay resistance, hard to fully grasp massive text in context window.

[^1]: https://archive.is/OJESS

[^2]: https://www.anthropic.com/claude/opus

[^3]: https://assets.anthropic.com/m/4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf

[^4]: https://www.anthropic.com/news/claude-opus-4-1
